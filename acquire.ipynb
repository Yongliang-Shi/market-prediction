{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import requests\n",
    "import env\n",
    "\n",
    "# import pandas_datareader.data as web\n",
    "# import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire Train Dataset Provided by Jane Street Market Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Acuqire the first 10_000 rows of the train dataset\n",
    "df_train_sample = pd.read_csv(\"Database/train.csv\", nrows=10000)\n",
    "\n",
    "# Print the shape of the sample\n",
    "df_train_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 2 records of the sample\n",
    "df_train_sample.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the last 2 records of the sample\n",
    "df_train_sample.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the data types of the sample\n",
    "df_train_sample.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there a column called 'action' in the train dataset? \n",
    "'action' in df_train_sample.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "1. `date` represents the day of the trade. \n",
    "2. `weight` and `resp` together represent a return on the trade.\n",
    "3. `ts_id` represents a time ordering.\n",
    "4. `resp` value as well as several other `resp_{1,2,3,4}` vlaues represent returns over different time horizons. \n",
    "5. However, the target variable `action` is not provided in the training dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to define the target variable `action`?\n",
    "1. Simply to use `resp` and perform the trade if it's positive.\n",
    "2. To use the product of `weight` and `resp` and perform the trade if it's positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Acquire the entire train dataset\n",
    "df_train = pd.read_csv(\"Database/train.csv\")\n",
    "\n",
    "# Print the memory usage\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**: To save memory while maintaining all precision, cast the float64 columns to float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create an iterator containing the names of the float64 columns\n",
    "colsf64 = df_train.select_dtypes(include='float64').columns\n",
    "colsf64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create the dictionary of the data types\n",
    "mapperf32 = {col: np.float32 for col in colsf64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Cast the float64 columns to float32\n",
    "df_train = df_train.astype(mapperf32)\n",
    "\n",
    "# Print the memory usage \n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create an iterator containing the names of the int64 columns\n",
    "colsi64 = df_train.select_dtypes(include='int64').columns\n",
    "colsi64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the last 5 rows of the train dataset\n",
    "df_train.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does using int32 change the precision of ts_id? \n",
    "\n",
    "print('float\\t\\t bytes')\n",
    "print(np.int64(2390490), '\\t', np.int64(2390490).nbytes)\n",
    "print(np.int32(2390490), '\\t', np.int32(2390490).nbytes)\n",
    "print(np.int16(2390490), '\\t', np.int16(2390490).nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**: Using int32 doesn't change the precision of the values in column ts_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary of the data types\n",
    "mapperi32 = {col: np.int32 for col in colsi64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Cast the int64 columns to int32\n",
    "df_train = df_train.astype(mapperi32)\n",
    "\n",
    "# Print the memory usage \n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**: The memory usage drops from 2.5 GB to 1.2 GB after changing the data types. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire data from Polygon API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the HTTP request\n",
    "\n",
    "polygon = env.polygon\n",
    "url = 'https://api.polygon.io/v2/aggs/ticker/AAPL/range/1/day/2021-01-14/2021-01-15?apiKey='\n",
    "url = url + polygon\n",
    "\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Break Down Polygon API**\n",
    "1. Base url: 'https://api.polygon.io'\n",
    "2. API version: '/v2'\n",
    "3. Relative ulr for the specific API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'v': 91382447.0,\n",
       "  'vw': 129.7361,\n",
       "  'o': 130.8,\n",
       "  'c': 128.91,\n",
       "  'h': 131,\n",
       "  'l': 128.76,\n",
       "  't': 1610600400000}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the query result in a list of dictionaries\n",
    "response.json()['results']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire the stock data from Yahoo finance\n",
    "- yf.Ticker().history()\n",
    "- yf.download\n",
    "- pandas data reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Through `yf.Ticker().history()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the Walmrt stock infomation\n",
    "\n",
    "wmt = yf.Ticker(\"WMT\") # the dtype of the wmt is a dictionary\n",
    "wmt # Return a Ticker object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get market data in the past 5 days\n",
    "\n",
    "hist = wmt.history(period=\"5d\")\n",
    "hist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "- The dtypes of the index is datetime.\n",
    "- Don't have the adjusted close price.\n",
    "- Doesn't support fetching data from multiple tickers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fetching data for multiple tickers using `yf.download()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string of multiple tickers\n",
    "tickers = 'AAPL WMT TSLA GE AMZN DB'\n",
    "\n",
    "# Acquire the adjusted closing price\n",
    "\n",
    "data = yf.download(tickers, '2020-12-01', '2020-12-04')['Adj Close']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "- The order of the stocks changes to alphabetical order.\n",
    "- The last day in the downloaded data is the previous day of end_date inputted in the yf.download method.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use pandas datareader to read stock data from yahoo finance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a list of the stocks you are interested\n",
    "stocks = ['AAPL', 'WMT', 'TSLA', 'GE', 'AMZN', 'DB']\n",
    "\n",
    "# Specify the start date and end date\n",
    "\n",
    "start_date = '2020-12-01'\n",
    "end_date = '2020-12-03'\n",
    "\n",
    "# Acquire the data\n",
    "data = web.DataReader(stocks, data_source='yahoo', start=start_date, end=end_date)['Adj Close']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "\n",
    "data.columns = stocks\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "- Take a little bit longer than the yf.download.\n",
    "- The order of the stocks remain the same in the dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the helper function to fetch the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquire metadata about the anonymized features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata about features\n",
    "df_features = pd.read_csv(\"Database/features.csv\")\n",
    "df_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 5 rows\n",
    "df_features.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
